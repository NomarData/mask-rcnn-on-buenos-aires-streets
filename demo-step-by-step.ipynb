{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mask R-CNN and YouTube",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [
        {
          "file_id": "1WxasznIcNsAds4RZBhSJUOrLladQH9vl",
          "timestamp": 1521333794814
        },
        {
          "file_id": "1mlLjSge8Jsqiu6SJVV9qZhCIhN6zZA2f",
          "timestamp": 1521039017956
        }
      ],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "0FZxzdnvlfvm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Using Mask R-CNN in Google Colab Notebooks\n",
        "\n",
        "---\n",
        "\n",
        "**Author:** Nicolás Metallo – http://www.nicolasmetallo.com\n",
        "\n",
        "Source:\n",
        "- https://arxiv.org/pdf/1703.06870.pdf\n",
        "- https://github.com/matterport/Mask_RCNN\n",
        "- https://github.com/facebookresearch/Detectron\n",
        "- https://research.fb.com/publications/mask-r-cnn/\n",
        "\n",
        "More info about Google Colab:\n",
        "- https://towardsdatascience.com/fast-ai-lesson-1-on-google-colab-free-gpu-d2af89f53604\n",
        "- https://medium.com/deep-learning-turkey/google-colab-free-gpu-tutorial-e113627b9f5d\n"
      ]
    },
    {
      "metadata": {
        "id": "tsZGJRAoNNYO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Setup environment"
      ]
    },
    {
      "metadata": {
        "id": "RZbk4lQjinox",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Configure Notebook"
      ]
    },
    {
      "metadata": {
        "id": "mvGF36DCTqmz",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Install the PyDrive wrapper & import libraries.\n",
        "# This only needs to be done once per notebook.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-Fd1qp6-psLb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Clone Git repository and setup coco-api\n",
        "\n",
        "---\n",
        "\n",
        "COCO is a large image dataset designed for object detection, segmentation, person keypoints detection, stuff segmentation, and caption generation. This package provides Matlab, Python, and Lua APIs that assists in loading, parsing, and visualizing the annotations in COCO.\n"
      ]
    },
    {
      "metadata": {
        "id": "3AQ2QNcqnDVb",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "## Clone Git repository\n",
        "!git clone https://github.com/matterport/Mask_RCNN.git object-detection\n",
        "  \n",
        "## Set repo as default folder\n",
        "os.chdir('object-detection')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qbFKa-WvR_QV",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "cellView": "both"
      },
      "cell_type": "code",
      "source": [
        "!pip install -U scikit-image\n",
        "!pip install -U cython\n",
        "!pip install git+https://github.com/waleedka/cocoapi.git#egg=pycocotools&subdirectory=PythonAPI\n",
        "!git clone https://github.com/pdollar/coco.git\n",
        "!cd coco/PythonAPI && make\n",
        "!cd coco/PythonAPI && make install\n",
        "!cd coco/PythonAPI && python3 setup.py install"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fh2BsS4MLqky",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Import libraries, model and load weights\n",
        "\n",
        "---\n",
        "\n",
        "A quick intro to using the pre-trained model to detect and segment objects."
      ]
    },
    {
      "metadata": {
        "id": "7wqVEao9Lqkz",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "import skimage.io\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import coco\n",
        "import utils\n",
        "import model as modellib\n",
        "\n",
        "%matplotlib inline \n",
        "\n",
        "# Root directory of the project\n",
        "ROOT_DIR = os.getcwd()\n",
        "\n",
        "# Directory to save logs and trained model\n",
        "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
        "\n",
        "# Local path to trained weights file\n",
        "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
        "# Download COCO trained weights from Releases if needed\n",
        "if not os.path.exists(COCO_MODEL_PATH):\n",
        "    utils.download_trained_weights(COCO_MODEL_PATH)\n",
        "\n",
        "## Configurations\n",
        "## We'll be using a model trained on the MS-COCO dataset. The configurations of this model are in the ```CocoConfig``` class in ```coco.py```.\n",
        "## For inferencing, modify the configurations a bit to fit the task. To do so, sub-class the ```CocoConfig``` class and override the attributes you need to change.\n",
        "\n",
        "class InferenceConfig(coco.CocoConfig):\n",
        "    # Set batch size to 1 since we'll be running inference on\n",
        "    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "\n",
        "config = InferenceConfig()\n",
        "config.display()\n",
        "\n",
        "## Create Model and Load Trained Weights\n",
        "\n",
        "# Create model object in inference mode.\n",
        "model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=config)\n",
        "\n",
        "# Load weights trained on MS-COCO\n",
        "model.load_weights(COCO_MODEL_PATH, by_name=True)\n",
        "\n",
        "# COCO Class names\n",
        "# Index of the class in the list is its ID. For example, to get ID of\n",
        "# the teddy bear class, use: class_names.index('teddy bear')\n",
        "class_names = ['BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',\n",
        "               'bus', 'train', 'truck', 'boat', 'traffic light',\n",
        "               'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',\n",
        "               'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',\n",
        "               'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n",
        "               'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
        "               'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
        "               'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',\n",
        "               'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
        "               'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
        "               'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n",
        "               'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
        "               'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',\n",
        "               'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',\n",
        "               'teddy bear', 'hair drier', 'toothbrush']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r9TfbIQRoZoZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Define functions\n",
        "\n",
        "---\n",
        "\n",
        "Source: https://www.youtube.com/watch?v=lLM8oAsi32g"
      ]
    },
    {
      "metadata": {
        "id": "QvDzKeBWrVy0",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "from os import path\n",
        "import time\n",
        "import PIL\n",
        "from PIL import Image\n",
        "import scipy.misc\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import collections"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d3iwAxBsoZYR",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Fix for bug in Google Colab\n",
        "# !pip install --no-cache-dir -I pillow\n",
        "\n",
        "def register_extension(id, extension):\n",
        "    PIL.Image.EXTENSION[extension.lower()] = id.upper()\n",
        "PIL.Image.register_extension = register_extension\n",
        "def register_extensions(id, extensions):\n",
        "    for extension in extensions:\n",
        "        register_extension(id, extension)\n",
        "PIL.Image.register_extensions = register_extensions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eytYhEOuopDS",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "## Functions to visualize detection results on the image\n",
        "\n",
        "def random_colors(N):\n",
        "    np.random.seed(2500)\n",
        "    colors = [tuple(255 * np.random.rand(3)) for _ in range(N)]    \n",
        "    return colors\n",
        "\n",
        "def apply_mask(image, mask, color, alpha=0.5):\n",
        "    \"\"\"apply mask to image\"\"\"\n",
        "    for n, c in enumerate(color):\n",
        "        image[:, :, n] = np.where(\n",
        "            mask == 1,\n",
        "            image[:, :, n] * (1 - alpha) + alpha * c,\n",
        "            image[:, :, n]\n",
        "        )\n",
        "    return image\n",
        "  \n",
        "def display_instances(image, boxes, masks, ids, names, scores, same = True):\n",
        "    \"\"\"\n",
        "        take the image and results and apply the mask, box, and Label\n",
        "    \"\"\"\n",
        "    n_instances = boxes.shape[0]\n",
        "    \n",
        "    if not n_instances:\n",
        "        print('NO INSTANCES TO DISPLAY')\n",
        "    else:\n",
        "        assert boxes.shape[0] == masks.shape[-1] == ids.shape[0]\n",
        "\n",
        "    if same is True:\n",
        "      colors = random_colors(len(class_names))    \n",
        "      for i in range(n_instances):\n",
        "        if not np.any(boxes[i]):\n",
        "          continue\n",
        "        y1,x1,y2,x2 = boxes[i]\n",
        "        label = names[ids[i]]\n",
        "        color = colors[ids[i]]\n",
        "        score = scores[i] if scores is not None else None\n",
        "        caption = '{} {:.1%}'.format(label, score) if score else label\n",
        "        mask = masks[:, :, i]\n",
        "        image = apply_mask(image, mask, color)\n",
        "        image = cv2.rectangle(image, (x1, y1), (x2, y2), color, 1)\n",
        "        image = cv2.putText(\n",
        "            image, caption, (x1, y1), cv2.FONT_HERSHEY_COMPLEX, 0.5, color, 1\n",
        "        )\n",
        "    else:\n",
        "      colors = random_colors(n_instances)\n",
        "      for i, color in enumerate(colors):\n",
        "        if not np.any(boxes[i]):\n",
        "          continue\n",
        "        y1, x1, y2, x2 = boxes[i]\n",
        "        label = names[ids[i]]\n",
        "        score = scores[i] if scores is not None else None\n",
        "        caption = '{} {:.1%}'.format(label, score) if score else label\n",
        "        mask = masks[:, :, i]\n",
        "        image = apply_mask(image, mask, color)\n",
        "        image = cv2.rectangle(image, (x1, y1), (x2, y2), color, 1)\n",
        "        image = cv2.putText(\n",
        "            image, caption, (x1, y1), cv2.FONT_HERSHEY_COMPLEX, 0.5, color, 1\n",
        "        )\n",
        "\n",
        "    # Add caption\n",
        "    counter = []\n",
        "    for _ in ids:\n",
        "      counter.append(names[_])\n",
        "    caption = str(collections.Counter(counter).most_common(3))\n",
        "    image = cv2.rectangle(image, (0, 0), (len(caption)*8, 40), (0,0,0), -1)\n",
        "    image = cv2.putText(image,caption,(10,25), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 1, cv2.LINE_AA)\n",
        "    \n",
        "    return image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W3uftOa_o4oW",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "## Function to input a video and output multiple frames with their detection\n",
        "\n",
        "def video_to_frames(input_vid, output_loc, max_fps = None):\n",
        "  # check if folder already exist otherwise mkdir\n",
        "  if not os.path.exists(output_loc):\n",
        "    os.mkdir(output_loc)\n",
        "    print(\"%s was created\" % output_loc)\n",
        "  # log the time\n",
        "  time_start = time.time()\n",
        "  # capture frame\n",
        "  cap = cv2.VideoCapture(input_vid)\n",
        "  count = 0\n",
        "  print('\\nRunning Mask R-CNN on %s' % input_vid)\n",
        "  \n",
        "  try:\n",
        "    while True:\n",
        "      status, image = cap.read()\n",
        "      # run detection\n",
        "      results = model.detect([image], verbose = 0)\n",
        "      # visualization\n",
        "      r = results[0]\n",
        "      result_image = display_instances(\n",
        "          image, r['rois'], r['masks'], r['class_ids'], class_names, r['scores']\n",
        "      )\n",
        "      cv2.imwrite(output_loc + \"/frame%04d.jpg\" % count, result_image)\n",
        "      count += 1\n",
        "      # print every 50 frames\n",
        "      if count % 50 == 0:\n",
        "        time_mid = time.time()\n",
        "        print(\"%d frames converted. Time elapsed: %d seconds.\" % (count, (time_mid - time_start)))\n",
        "      # set upper limit\n",
        "      if not max_fps == None:\n",
        "        if count > max_fps:\n",
        "          break\n",
        "\n",
        "  except Exception as e:\n",
        "    print(\"There was an error!\")\n",
        "    print(e)\n",
        " \n",
        "  cap.release()\n",
        "\t# log the time again\n",
        "  time_end = time.time()\n",
        "  print(\"%d frames converted at %d frames per second\\n\" % (count, (count/(time_end - time_start))))\n",
        "  print(\"Conversion time: %d seconds.\" % (time_end - time_start))\n",
        "  \n",
        "def single_frame_detection(path, title=\"\", figsize=(16, 16), ax=None):  \n",
        "  image = scipy.misc.imread(path)\n",
        "  \n",
        "  if not ax:\n",
        "        _, ax = plt.subplots(1, figsize=figsize)\n",
        "  \n",
        "  # Show area outside image boundaries.\n",
        "  height, width = image.shape[:2]\n",
        "  ax.set_ylim(height + 10, -10)\n",
        "  ax.set_xlim(-10, width + 10)\n",
        "  ax.axis('off')\n",
        "  ax.set_title(title)\n",
        "  \n",
        "  # Run detection\n",
        "  results = model.detect([image], verbose=0)\n",
        "  # Visualize results\n",
        "  r = results[0]\n",
        "  result_image = display_instances(image, r['rois'], r['masks'], r['class_ids'], \n",
        "                            class_names, r['scores'])\n",
        "\n",
        "  plt.imshow(result_image)\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tpA4cDaobXiy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Download mp4 video from YouTube\n",
        "---\n",
        "Source: https://github.com/rg3/youtube-dl and https://github.com/rg3/youtube-dl/issues/5192"
      ]
    },
    {
      "metadata": {
        "id": "4KjcJxtJbRjv",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from __future__ import unicode_literals\n",
        "!pip install --upgrade youtube-dl # install if you don't have it\n",
        "import youtube_dl\n",
        "\n",
        "def YouTube_download(url):\n",
        "  ydl_opts = {\n",
        "      'outtmpl': 'yt-video.%(ext)s'\n",
        "  }\n",
        "  with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n",
        "    ydl.download([url])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Sy0wyo4Ytni_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Frames to video and upload/download function\n",
        "\n",
        "---\n",
        "\n",
        "Source: http://www.xavierdupre.fr/blog/2016-03-30_nojs.html "
      ]
    },
    {
      "metadata": {
        "id": "NeoksmY6tmrr",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "## Function to combine frames into a video\n",
        "\n",
        "def frames_to_video(input_folder, outvid=None, fps=30, size=None,\n",
        "               is_color=True, format='MP4V'):\n",
        "    \"\"\"\n",
        "    Create a video from a list of images.\n",
        " \n",
        "    @param      outvid      output video\n",
        "    @param      images      list of images to use in the video\n",
        "    @param      fps         frame per second\n",
        "    @param      size        size of each frame\n",
        "    @param      is_color    color\n",
        "    @param      format      see http://www.fourcc.org/codecs.php\n",
        "    @return                 see http://opencv-python-tutroals.readthedocs.org/en/latest/py_tutorials/py_gui/py_video_display/py_video_display.html\n",
        " \n",
        "    The function relies on http://opencv-python-tutroals.readthedocs.org/en/latest/.\n",
        "    By default, the video will have the size of the first image.\n",
        "    It will resize every image to this size before adding them to the video.\n",
        "    \"\"\"\n",
        "    from cv2 import VideoWriter, VideoWriter_fourcc, imread, resize\n",
        "    fourcc = VideoWriter_fourcc(*format)\n",
        "    image_dir = sorted(os.listdir(input_folder))\n",
        "    vid = None\n",
        "    for i in image_dir:\n",
        "      image = os.path.join(input_folder, i)\n",
        "      if not os.path.exists(image):\n",
        "        raise FileNotFoundError(image)\n",
        "      img = imread(image)\n",
        "      if vid is None:\n",
        "        if size is None:\n",
        "          size = img.shape[1], img.shape[0]\n",
        "          vid = VideoWriter('out.mp4', fourcc, float(fps), size, is_color)\n",
        "      if size[0] != img.shape[1] and size[1] != img.shape[0]:\n",
        "        img = resize(img, size)\n",
        "      vid.write(img)\n",
        "    vid.release()\n",
        "\n",
        "# Function to download generated output\n",
        "\n",
        "def download_output(exportAs = \"MP4\"):\n",
        "  from google.colab import files\n",
        "  import shutil\n",
        "  \n",
        "  if exportAs is \"MP4\":\n",
        "    files.download(\"out.mp4\")\n",
        "  else:\n",
        "    shutil.make_archive(\"youtube-object-detection\", 'zip', IMAGE_DIR)\n",
        "    files.download(\"youtube-object-detection.zip\")\n",
        "    \n",
        "def upload():\n",
        "  from google.colab import files\n",
        "  uploaded = files.upload()\n",
        "  for fn in uploaded.keys():\n",
        "    print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "        name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QVrBU8NoLqlJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Run mask R-CNN on video stream\n",
        "\n",
        "---\n",
        "Example videos:\n",
        "- https://www.youtube.com/watch?v=bAhprdemJKE\n",
        "- https://www.youtube.com/watch?v=nosl1lxFyng\n",
        "- https://www.youtube.com/watch?v=vUpDPz3Z8NM"
      ]
    },
    {
      "metadata": {
        "id": "U9Bwi5zadUAZ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "IMAGE_DIR = \"output-dir\" # dir to save images\n",
        "\n",
        "# Download YT video\n",
        "YouTube_download(\"https://www.youtube.com/watch?v=vUpDPz3Z8NM\")\n",
        "\n",
        "# Run detection and output frames\n",
        "video_to_frames(input_vid = \"yt-video.mp4\", output_loc = IMAGE_DIR, max_fps=30*60)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oRRjDwg_j9J0",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Combine frames into video\n",
        "frames_to_video(IMAGE_DIR)\n",
        "\n",
        "# Download result\n",
        "download_output()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ogtiJCBICRNh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Run Mask R-CNN on single picture"
      ]
    },
    {
      "metadata": {
        "id": "ci6MZMpyALxj",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# upload your own photo\n",
        "upload()\n",
        "\n",
        "# Single frame detection\n",
        "single_frame_detection(\"trafico-buenos-aires.jpg\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}